{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "\n",
    "import yaml\n",
    "import datastorewrapper\n",
    "from ipyparallel import Client\n",
    "\n",
    "# Folders\n",
    "if not os.path.exists('logs'): os.makedirs('logs')\n",
    "if not os.path.exists('results'): os.makedirs('results')\n",
    "\n",
    "# Logger\n",
    "LOGS_FILE = 'logs/laser.log'\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.DEBUG)\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "handler = logging.FileHandler(LOGS_FILE)\n",
    "handler.setLevel(logging.INFO)\n",
    "LOGGER.addHandler(handler)\n",
    "\n",
    "   \n",
    "# Donwload files using datastorewrapper\n",
    "def ds_download_files(ds_repo, ds_resource):\n",
    "    file_type = None\n",
    "    raw_files_dir = None\n",
    "    \n",
    "    datastore = datastorewrapper.Datastore()\n",
    "    repo_files = datastore.files(ds_repo, ds_resource)\n",
    "    if repo_files:\n",
    "        line1 = repo_files[0]\n",
    "        raw_files_dir = \"/\".join(line1.split(\"/\")[:-1])\n",
    "        file_type = line1.split('.')[-1:][0]\n",
    "        \n",
    "    return raw_files_dir, file_type\n",
    "\n",
    "# Util for forloop\n",
    "def drange(start, stop, step):\n",
    "    r = start\n",
    "    while r < stop:\n",
    "        yield r\n",
    "        r += step\n",
    "\n",
    "# Get jobs list\n",
    "def get_jobs_list(ds_repo, ds_resource):\n",
    "    # Download files\n",
    "    raw_files_dir, file_type = ds_download_files(ds_repo, ds_resource)\n",
    "    if raw_files_dir is None:\n",
    "        return None\n",
    "\n",
    "    # Parameters: (TODO: It should come from metadata)\n",
    "    # x, y: Values for x and y in the form of [from, to]\n",
    "    # m: order of permutation entropy (e.g. 5)\n",
    "    # t: delay of permutation entropy (e.g. 2)\n",
    "    x = [0, 1, 1]  # phase sectin current [start, stop, step]\n",
    "    y = [15, 16, 0.1]  # dfb injection current [start, stop, step]\n",
    "    z = [9, 10, 0.1]   # g/a section current [start, stop, step]\n",
    "    m = 3\n",
    "    t = 2\n",
    "\n",
    "    n = 0\n",
    "    jobs_list = []\n",
    "    for pha in drange(x[0], x[1], x[2]):\n",
    "        for dfb in drange(y[0], y[1], y[2]):\n",
    "            for gas in drange(z[0], z[1], z[2]):\n",
    "                i = \"{0:05.2f}-{1:05.2f}-{2:05.2f}\".format(pha, dfb, gas)\n",
    "                job_data = {\"raw_files_dir\": raw_files_dir, \"file_type\": file_type, \n",
    "                            \"pha\": pha, \"dfb\": dfb, \"gas\": gas, \"m\": m, \"t\": t}\n",
    "                jobs_list.append(job_data)\n",
    "                n += 1\n",
    "                #if n > 2:\n",
    "                #    break\n",
    "    return jobs_list\n",
    "\n",
    "def worker(job_data):\n",
    "    import os\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    \n",
    "    # Read parameters\n",
    "    raw_files_dir = job_data.get(\"raw_files_dir\")\n",
    "    file_type = job_data.get(\"file_type\")\n",
    "    pha = job_data.get(\"pha\")\n",
    "    dfb = job_data.get(\"dfb\")\n",
    "    gas = job_data.get(\"gas\")\n",
    "    m = job_data.get(\"m\")\n",
    "    t = job_data.get(\"t\")\n",
    "\n",
    "    pe = 0\n",
    "    w_pe = 0\n",
    "    filename = '{0}/IPH{1:05.2f}DFB{2:05.2f}GAS{3:05.2f}.{4}'.format(raw_files_dir, pha, dfb, gas, file_type)\n",
    "    if os.path.exists(filename):\n",
    "        raw_data = []\n",
    "        with h5py.File(filename) as h5f:\n",
    "            for ds in h5f:\n",
    "                for row in h5f[ds][()]:\n",
    "                    raw_data.append(float(row[0]))\n",
    "\n",
    "\n",
    "        perms = dict()\n",
    "        w_perms = dict()\n",
    "        for a in range(len(raw_data) - t*(m-1)):\n",
    "            v = tuple(np.argsort(raw_data[a:(a + t*(m-1) + 1):t]))\n",
    "            w = (1./m)*np.sum(((raw_data[a:(a + t*(m-1) + 1):t]) - np.mean(raw_data[a:(a + t*(m-1) + 1):t]))**2)\n",
    "            if v in perms:\n",
    "                perms[v] += 1\n",
    "                w_perms[v] += 1*w\n",
    "            else:\n",
    "                perms[v] = 1\n",
    "                w_perms[v] = w\n",
    "\n",
    "        c = np.array(list(perms.values()))\n",
    "        w_c = np.array(list(w_perms.values()))\n",
    "        p = c / float(np.sum(c))\n",
    "        w_p = w_c / float(np.sum(w_c))\n",
    "        pe = -np.sum(np.dot(p, np.log(p)))\n",
    "        w_pe = -np.sum(np.dot(w_p, np.log(w_p)))\n",
    "        pe = pe / np.log(np.math.factorial(m))\n",
    "        w_pe = w_pe / np.log(np.math.factorial(m))\n",
    "\n",
    "    # Update results\n",
    "    job_results = {'pha': round(pha,1), 'dfb': round(dfb,1), 'gas': round(gas,1), 'pe': pe, 'w_pe': w_pe}\n",
    "\n",
    "    return job_results\n",
    "\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    # Get jobs list\n",
    "    LOGGER.info(\"Geting jobs list\")\n",
    "    ds_repo = \"bdkd-laser-public\"\n",
    "    ds_resource = \"Multisection_SL_test\"\n",
    "    jobs_list = get_jobs_list(ds_repo, ds_resource)\n",
    "    if jobs_list is None:\n",
    "        print 'No files found. Something is wrong with \"{0}\" dataset'.format(ds_resource)\n",
    "        return\n",
    "\n",
    "    # Ipython parallel setup\n",
    "    profile_dir = \"/home/data/files/profile\"\n",
    "    rc = Client(profile_dir=profile_dir)\n",
    "    dview = rc.direct_view()\n",
    "    dview.block=False\n",
    "\n",
    "    # Scheduling jobs\n",
    "    LOGGER.info(\"Scheduling: {0} jobs\".format(len(jobs_list)))\n",
    "    jobs_sent = dview.map(worker, jobs_list)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Waiting for results\n",
    "    LOGGER.info(\"Waiting for results\")\n",
    "    dview.wait(jobs_sent)\n",
    "\n",
    "    # Collecting results\n",
    "    LOGGER.info(\"Collecting results\")\n",
    "    wip_simulations = jobs_sent.get()\n",
    "    list_pe = []\n",
    "    for i in wip_simulations:\n",
    "        list_pe.append((i.get('pha'), i.get('dfb'), i.get('gas'), i.get('pe'), i.get('w_pe')))\n",
    "\n",
    "    # Save results to csv file\n",
    "    results_file = \"results/results_{0}.csv\".format(ds_resource.replace(\" \", \"\").replace(\"/\", \"_\"))\n",
    "    LOGGER.info(\"Saving results into: {0}\".format(results_file))\n",
    "    with open(results_file, 'w') as fp:\n",
    "        a = csv.writer(fp, delimiter=',')\n",
    "        a.writerow(('pha', 'dfb', 'gas', 'pe', 'wpe'))\n",
    "        a.writerows(list_pe)\n",
    "\n",
    "# 2 processors, 0.25 cpu each\n",
    "# dview.block=True\n",
    "#\n",
    "# Run\n",
    "t1 = datetime.datetime.now()\n",
    "a = main()\n",
    "t2 = datetime.datetime.now()\n",
    "LOGGER.info(\"Time taken = %s \" % (t2-t1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
